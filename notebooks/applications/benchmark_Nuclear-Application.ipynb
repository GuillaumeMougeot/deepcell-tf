{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "This notebook is part of the `deepcell-tf` documentation: https://deepcell.readthedocs.io/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "# Nuclear segmentation and tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "from skimage import io\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "## Nuclear Segmentation\n",
    "\n",
    "### Initialize nuclear model\n",
    "\n",
    "The application will download pretrained weights for nuclear segmentation. For more information about application objects, please see our [documentation](https://deepcell.readthedocs.io/en/master/API/deepcell.applications.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://deepcell-data.s3-us-west-1.amazonaws.com/saved-models/NuclearSegmentation-3.tar.gz\n",
      "95150080/95148111 [==============================] - 10s 0us/step\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from deepcell.applications import NuclearSegmentation\n",
    "\n",
    "app = NuclearSegmentation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "## Use the application to generate labeled images\n",
    "\n",
    "Typically, neural networks perform best on test data that is similar to the training data. In the realm of biological imaging, the most common difference between datasets is the resolution of the data measured in microns per pixel. The training resolution of the model can be identified using `app.model_mpp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Resolution: 0.65 microns per pixel\n"
     ]
    }
   ],
   "source": [
    "print('Training Resolution:', app.model_mpp, 'microns per pixel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "The resolution of the input data can be specified in `app.predict` using the `image_mpp` option. The `Application` will rescale the input data to match the training resolution and then rescale to the original size before returning the labeled image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a 3D image\n",
    "DATASET_DIR='../../data/'\n",
    "print(os.listdir(DATASET_DIR))\n",
    "IMAGES_DIR = os.path.join(DATASET_DIR,'val_data','#3c NUCLEAR MORPHOLOGY - RAW')\n",
    "images_names = os.listdir(IMAGES_DIR)\n",
    "images = io.imread(IMAGES_DIR + '/' + images_names[1])\n",
    "\n",
    "# loads one slice only\n",
    "# image = images[len(images)//2+4]\n",
    "\n",
    "# converts the image to fit it to the network\n",
    "images = np.array([cv2.convertScaleAbs(image, alpha=(255.0/65535.0)) for image in images])\n",
    "images = images.astype(np.uint8)\n",
    "\n",
    "plt.imshow(images[len(images)//2])\n",
    "plt.show()\n",
    "\n",
    "images = np.expand_dims(images,-1)\n",
    "# image = np.expand_dims(image, 0)\n",
    "print(images.shape)\n",
    "\n",
    "# prediction\n",
    "y_pred = app.predict(images, image_mpp=.6)\n",
    "\n",
    "print(y_pred.shape)\n",
    "plt.imshow(y_pred[len(y_pred)//2,...,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we keep only the biggest nuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, counts = np.unique(y_pred,return_counts=True)\n",
    "print(\"Number of predicted labels: {}\".format(len(labels)))\n",
    "\n",
    "max_count_idx = np.argmax(counts[1:]) # index of the maximum\n",
    "print(\"Maximum index: {}\".format(max_count_idx))\n",
    "# the other indices are set to zeros in the images\n",
    "reformat_pred = np.where(y_pred == max_count_idx+1, y_pred, y_pred * 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(reformat_pred[len(y_pred)//2-5,...,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loop over the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_square(images):\n",
    "    \"\"\"\n",
    "    adds zeros to transform the image in a square.\n",
    "    \"\"\"\n",
    "    n,x,y,c = images.shape  \n",
    "    nbof_zeros = []\n",
    "    if x > y:\n",
    "        nbof_zeros_before = (x-y)//2 \n",
    "        nbof_zeros_after = (x-y)//2 if (x-y)%2==0 else (x-y)//2 + 1\n",
    "        nbof_zeros = [[0,0],[0,0],[nbof_zeros_before,nbof_zeros_after],[0,0]]\n",
    "        images = np.pad(images, nbof_zeros, 'constant', constant_values=0)\n",
    "    elif y > x:\n",
    "        nbof_zeros_before = (y-x)//2 \n",
    "        nbof_zeros_after = (y-x)//2 if (y-x)%2==0 else (y-x)//2 + 1\n",
    "        nbof_zeros = [[0,0],[nbof_zeros_before,nbof_zeros_after],[0,0],[0,0]]\n",
    "        images = np.pad(images, nbof_zeros, 'constant', constant_values=0)\n",
    "    \n",
    "    return images, nbof_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the list of file names\n",
    "DATASET_DIR='../../data/'\n",
    "IMAGES_DIR = os.path.join(DATASET_DIR,'val_data','#3c NUCLEAR MORPHOLOGY - RAW')\n",
    "images_names = os.listdir(IMAGES_DIR)\n",
    "\n",
    "for i in range(len(images_names)):\n",
    "    \n",
    "    # read the images\n",
    "    print(\"current index: {}/{}\".format(i,len(images_names)))\n",
    "    images = io.imread(IMAGES_DIR + '/' + images_names[i])\n",
    "\n",
    "    # loads one slice only\n",
    "    # image = images[len(images)//2+4]\n",
    "\n",
    "    # converts the image to fit it to the network\n",
    "    images = np.array([cv2.convertScaleAbs(image, alpha=(255.0/65535.0)) for image in images])\n",
    "    images = images.astype(np.uint8)\n",
    "\n",
    "    # adapt images dimension to fit to the network\n",
    "    # the network can take in some cases a non-squared input but I did not managed to find \n",
    "    # under what exact conditions it is possible.\n",
    "    images = np.expand_dims(images,-1)\n",
    "    images, nbof_zeros = pad_square(images) \n",
    "    assert images.shape[1]==images.shape[2]\n",
    "\n",
    "    # prediction\n",
    "    y_pred = app.predict(images)\n",
    "    print(y_pred.shape)\n",
    "    \n",
    "    # crop the prediction back to the orginal size\n",
    "    if nbof_zeros != []:\n",
    "        n0,x0,y0,c0 = nbof_zeros\n",
    "        n,x,y,c = images.shape\n",
    "        images = images[:,x0[0]:x-x0[1],y0[0]:y-y0[0],:]\n",
    "    print(images.shape)\n",
    "    \n",
    "    # remove multiple labels\n",
    "    labels, counts = np.unique(y_pred,return_counts=True)\n",
    "    \n",
    "    # save only if enough labels in the picture\n",
    "    if len(labels) > 1: \n",
    "        \n",
    "        # index of the maximum\n",
    "        max_count_idx = np.argmax(counts[1:]) \n",
    "        \n",
    "        # the other indices are set to zeros in the images\n",
    "        reformat_pred = np.where(y_pred == max_count_idx+1, y_pred, y_pred * 0)\n",
    "\n",
    "        # saves the images output\n",
    "        io.imsave(DATASET_DIR+'deepcell_output/'+images_names[i], np.squeeze(reformat_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Save labeled images as a gif to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(im1, im2, vmin, vmax):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(im1)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('Raw')\n",
    "    ax[1].imshow(im2, cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    ax[1].set_title('Segmented')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    fig.canvas.draw()  # draw the canvas, cache the renderer\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    plt.close(fig)\n",
    "\n",
    "    return image\n",
    "\n",
    "imageio.mimsave(\n",
    "    './labeled.gif',\n",
    "    [plot(x[i,...,0], y_pred[i,...,0], y_pred.min(), y_pred.max())\n",
    "     for i in range(y_pred.shape[0])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
